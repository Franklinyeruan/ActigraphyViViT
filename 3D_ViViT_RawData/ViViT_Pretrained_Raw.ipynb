{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ViViT Model Pretrained\n",
        "available to train with Google CPU TPUv2"
      ],
      "metadata": {
        "id": "7FaPdtq10XV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%reset -f"
      ],
      "metadata": {
        "id": "vMwD6_35DyTB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Retrieve the token from Colab secrets\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "\n",
        "# Print to verify\n",
        "print(f\"HF token is: {hf_token}\")\n",
        "\n",
        "# Set the token as an environment variable\n",
        "os.environ['HUGGINGFACE_TOKEN'] = hf_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjjIaiak628b",
        "outputId": "a573e878-5c45-42d5-bb71-3e086d7845fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HF token is: 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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqDy9pMy0NgP",
        "outputId": "c2ac3129-f082-4070-db89-b8da8be1b349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# write where you want to save all your files\n",
        "root = \"/content/drive/MyDrive/ActigraphyTransformer/Modeling/Class Benzos/Raw Data/ViViT_Pretrained\"\n",
        "print(\"root directory is {}\".format(root))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHmOa3PV1EQg",
        "outputId": "83f6a622-ec0e-4821-c4f3-e3f33afe0cd0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root directory is /content/drive/MyDrive/ActigraphyTransformer/Modeling/Class Benzos/Raw Data/ViViT_Pretrained\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Connects to TPU"
      ],
      "metadata": {
        "id": "msu8FS7P0XZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyarrow fastparquet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gffhbQVz1Z6q",
        "outputId": "0fbafca5-da9e-4bc3-de3a-50eeafe0540c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (14.0.2)\n",
            "Collecting fastparquet\n",
            "  Downloading fastparquet-2024.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from fastparquet) (2.0.3)\n",
            "Collecting cramjam>=2.3 (from fastparquet)\n",
            "  Downloading cramjam-2.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet) (2023.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet) (24.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
            "Installing collected packages: cramjam, fastparquet\n",
            "Successfully installed cramjam-2.8.3 fastparquet-2024.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY_RMumPLx1P",
        "outputId": "c37dbbb5-4e66-4d17-e762-5341b1cbad77"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch pandas scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPiLuJl41e9E",
        "outputId": "a29f61b4-86da-45d7-f720-8102ba4e49c6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ig_XiAx3Vn0",
        "outputId": "7d7c15ee-d3cf-49b8-bf1f-8d78e4c29247"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install cloud-tpu-client\n",
        "# !pip install torch_xla"
      ],
      "metadata": {
        "id": "JkcYJoLQ3f8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Importing\n",
        "\n",
        "# Packages\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "#from keras.layers.embeddings import Embedding\n",
        "from keras.metrics import AUC\n",
        "\n",
        "# Tf\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import random\n",
        "\n",
        "# Import Layers\n",
        "from keras.layers import ConvLSTM2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Activation\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import MaxPooling3D"
      ],
      "metadata": {
        "id": "TuoyjdvJ1iRB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## SEEDS\n",
        "\n",
        "# Hard Code Random Seeds.\n",
        "r1 = 0\n",
        "r2 = 1\n",
        "\n",
        "# Set Random Seed\n",
        "random.seed(r1)\n",
        "tf.random.set_seed(r2)"
      ],
      "metadata": {
        "id": "PMHK-lRj1jI2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the Data"
      ],
      "metadata": {
        "id": "HHvYS-C03Bek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data_all = pd.read_parquet(\"/content/drive/MyDrive/ActigraphyTransformer/Data/Actigraphy/WideSeqnActi_AndMeds_ALL.parq\")"
      ],
      "metadata": {
        "id": "g8gVYNX11jNN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "N5YCNZdKw_oU",
        "outputId": "22001dc5-1b2d-499e-b624-9f015f60b038"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         PAXMTSM point 1  PAXMTSM point 2  PAXMTSM point 3  PAXMTSM point 4  \\\n",
              "SEQN                                                                          \n",
              "21005.0            0.000            0.000            0.000            0.000   \n",
              "21006.0           56.000           47.000          313.000          557.000   \n",
              "21007.0            0.000            0.000            0.000            0.000   \n",
              "21008.0           32.000           52.000            0.000            0.000   \n",
              "21009.0            0.000            0.000            0.000            0.000   \n",
              "...                  ...              ...              ...              ...   \n",
              "83725.0           86.019          110.070           33.784           31.568   \n",
              "83727.0           15.516            4.113            7.335            5.231   \n",
              "83729.0            4.226            2.949            6.144            5.478   \n",
              "83730.0           23.091           42.873           63.587           31.802   \n",
              "83731.0           17.450            5.949           11.557           10.180   \n",
              "\n",
              "         PAXMTSM point 5  PAXMTSM point 6  PAXMTSM point 7  PAXMTSM point 8  \\\n",
              "SEQN                                                                          \n",
              "21005.0            0.000            0.000            0.000            0.000   \n",
              "21006.0           45.000            0.000            0.000           11.000   \n",
              "21007.0            0.000            0.000            0.000            0.000   \n",
              "21008.0            0.000            0.000           21.000            0.000   \n",
              "21009.0            0.000            0.000            0.000            0.000   \n",
              "...                  ...              ...              ...              ...   \n",
              "83725.0           29.926           15.809           47.060           44.536   \n",
              "83727.0            7.807            6.679           11.874            7.941   \n",
              "83729.0            1.360            1.183            7.658            1.693   \n",
              "83730.0           53.440           60.810           19.128           12.082   \n",
              "83731.0            5.762           14.062           12.185           14.427   \n",
              "\n",
              "         PAXMTSM point 9  PAXMTSM point 10  ...  PAXMTSM point 10074  \\\n",
              "SEQN                                        ...                        \n",
              "21005.0            0.000             0.000  ...                0.000   \n",
              "21006.0            0.000             0.000  ...                0.000   \n",
              "21007.0            0.000             0.000  ...                0.000   \n",
              "21008.0           58.000           149.000  ...                0.000   \n",
              "21009.0            0.000             0.000  ...                0.000   \n",
              "...                  ...               ...  ...                  ...   \n",
              "83725.0           34.368            51.377  ...               34.280   \n",
              "83727.0            6.229             5.363  ...               20.148   \n",
              "83729.0           10.427             7.167  ...                0.000   \n",
              "83730.0           42.624            18.605  ...                9.022   \n",
              "83731.0            8.205            13.543  ...               33.768   \n",
              "\n",
              "         PAXMTSM point 10075  PAXMTSM point 10076  PAXMTSM point 10077  \\\n",
              "SEQN                                                                     \n",
              "21005.0                0.000                0.000                0.000   \n",
              "21006.0                0.000                0.000                0.000   \n",
              "21007.0                0.000                0.000                0.000   \n",
              "21008.0                0.000                0.000                0.000   \n",
              "21009.0                0.000                0.000                0.000   \n",
              "...                      ...                  ...                  ...   \n",
              "83725.0               24.674               33.506               35.667   \n",
              "83727.0               36.052               31.317               14.952   \n",
              "83729.0                0.000                0.000                0.000   \n",
              "83730.0                5.042               12.994               86.261   \n",
              "83731.0               26.015               18.035                4.439   \n",
              "\n",
              "         PAXMTSM point 10078  PAXMTSM point 10079  PAXMTSM point 10080  \\\n",
              "SEQN                                                                     \n",
              "21005.0                0.000                0.000                0.000   \n",
              "21006.0                0.000                0.000                0.000   \n",
              "21007.0              169.000                0.000                0.000   \n",
              "21008.0                0.000                0.000                0.000   \n",
              "21009.0                0.000                0.000                0.000   \n",
              "...                      ...                  ...                  ...   \n",
              "83725.0               25.596               39.156               25.891   \n",
              "83727.0                9.671               13.229                9.351   \n",
              "83729.0                0.000                0.000                0.000   \n",
              "83730.0               38.111               21.436               44.346   \n",
              "83731.0                6.546               26.229                1.087   \n",
              "\n",
              "         Taking_SSRI  Taking_Benzodiazepine  Taking_Psychotropic  \n",
              "SEQN                                                              \n",
              "21005.0            0                      0                    0  \n",
              "21006.0            0                      0                    0  \n",
              "21007.0            0                      0                    0  \n",
              "21008.0            0                      0                    0  \n",
              "21009.0            0                      0                    0  \n",
              "...              ...                    ...                  ...  \n",
              "83725.0            0                      0                    0  \n",
              "83727.0            0                      0                    0  \n",
              "83729.0            0                      0                    0  \n",
              "83730.0            0                      0                    0  \n",
              "83731.0            0                      0                    0  \n",
              "\n",
              "[29307 rows x 10083 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c4df660-a12d-469e-a732-843e80c5d1fd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PAXMTSM point 1</th>\n",
              "      <th>PAXMTSM point 2</th>\n",
              "      <th>PAXMTSM point 3</th>\n",
              "      <th>PAXMTSM point 4</th>\n",
              "      <th>PAXMTSM point 5</th>\n",
              "      <th>PAXMTSM point 6</th>\n",
              "      <th>PAXMTSM point 7</th>\n",
              "      <th>PAXMTSM point 8</th>\n",
              "      <th>PAXMTSM point 9</th>\n",
              "      <th>PAXMTSM point 10</th>\n",
              "      <th>...</th>\n",
              "      <th>PAXMTSM point 10074</th>\n",
              "      <th>PAXMTSM point 10075</th>\n",
              "      <th>PAXMTSM point 10076</th>\n",
              "      <th>PAXMTSM point 10077</th>\n",
              "      <th>PAXMTSM point 10078</th>\n",
              "      <th>PAXMTSM point 10079</th>\n",
              "      <th>PAXMTSM point 10080</th>\n",
              "      <th>Taking_SSRI</th>\n",
              "      <th>Taking_Benzodiazepine</th>\n",
              "      <th>Taking_Psychotropic</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SEQN</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21005.0</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21006.0</th>\n",
              "      <td>56.000</td>\n",
              "      <td>47.000</td>\n",
              "      <td>313.000</td>\n",
              "      <td>557.000</td>\n",
              "      <td>45.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>11.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21007.0</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>169.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21008.0</th>\n",
              "      <td>32.000</td>\n",
              "      <td>52.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>21.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>58.000</td>\n",
              "      <td>149.000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21009.0</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83725.0</th>\n",
              "      <td>86.019</td>\n",
              "      <td>110.070</td>\n",
              "      <td>33.784</td>\n",
              "      <td>31.568</td>\n",
              "      <td>29.926</td>\n",
              "      <td>15.809</td>\n",
              "      <td>47.060</td>\n",
              "      <td>44.536</td>\n",
              "      <td>34.368</td>\n",
              "      <td>51.377</td>\n",
              "      <td>...</td>\n",
              "      <td>34.280</td>\n",
              "      <td>24.674</td>\n",
              "      <td>33.506</td>\n",
              "      <td>35.667</td>\n",
              "      <td>25.596</td>\n",
              "      <td>39.156</td>\n",
              "      <td>25.891</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83727.0</th>\n",
              "      <td>15.516</td>\n",
              "      <td>4.113</td>\n",
              "      <td>7.335</td>\n",
              "      <td>5.231</td>\n",
              "      <td>7.807</td>\n",
              "      <td>6.679</td>\n",
              "      <td>11.874</td>\n",
              "      <td>7.941</td>\n",
              "      <td>6.229</td>\n",
              "      <td>5.363</td>\n",
              "      <td>...</td>\n",
              "      <td>20.148</td>\n",
              "      <td>36.052</td>\n",
              "      <td>31.317</td>\n",
              "      <td>14.952</td>\n",
              "      <td>9.671</td>\n",
              "      <td>13.229</td>\n",
              "      <td>9.351</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83729.0</th>\n",
              "      <td>4.226</td>\n",
              "      <td>2.949</td>\n",
              "      <td>6.144</td>\n",
              "      <td>5.478</td>\n",
              "      <td>1.360</td>\n",
              "      <td>1.183</td>\n",
              "      <td>7.658</td>\n",
              "      <td>1.693</td>\n",
              "      <td>10.427</td>\n",
              "      <td>7.167</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83730.0</th>\n",
              "      <td>23.091</td>\n",
              "      <td>42.873</td>\n",
              "      <td>63.587</td>\n",
              "      <td>31.802</td>\n",
              "      <td>53.440</td>\n",
              "      <td>60.810</td>\n",
              "      <td>19.128</td>\n",
              "      <td>12.082</td>\n",
              "      <td>42.624</td>\n",
              "      <td>18.605</td>\n",
              "      <td>...</td>\n",
              "      <td>9.022</td>\n",
              "      <td>5.042</td>\n",
              "      <td>12.994</td>\n",
              "      <td>86.261</td>\n",
              "      <td>38.111</td>\n",
              "      <td>21.436</td>\n",
              "      <td>44.346</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83731.0</th>\n",
              "      <td>17.450</td>\n",
              "      <td>5.949</td>\n",
              "      <td>11.557</td>\n",
              "      <td>10.180</td>\n",
              "      <td>5.762</td>\n",
              "      <td>14.062</td>\n",
              "      <td>12.185</td>\n",
              "      <td>14.427</td>\n",
              "      <td>8.205</td>\n",
              "      <td>13.543</td>\n",
              "      <td>...</td>\n",
              "      <td>33.768</td>\n",
              "      <td>26.015</td>\n",
              "      <td>18.035</td>\n",
              "      <td>4.439</td>\n",
              "      <td>6.546</td>\n",
              "      <td>26.229</td>\n",
              "      <td>1.087</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29307 rows × 10083 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c4df660-a12d-469e-a732-843e80c5d1fd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c4df660-a12d-469e-a732-843e80c5d1fd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c4df660-a12d-469e-a732-843e80c5d1fd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fa26a2a1-9a28-45d3-bd08-67949d9e0d01\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa26a2a1-9a28-45d3-bd08-67949d9e0d01')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fa26a2a1-9a28-45d3-bd08-67949d9e0d01 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0d639afd-f0c5-4b6c-b7b2-a620573a40df\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data_all')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0d639afd-f0c5-4b6c-b7b2-a620573a40df button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data_all');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_all"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Choose Variable"
      ],
      "metadata": {
        "id": "AV-IS4a63M5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Spit actigraphy X and then y\n",
        "chosen_y = data_all['Taking_Benzodiazepine']\n",
        "chosen_X = data_all.drop(columns=['Taking_SSRI', 'Taking_Benzodiazepine', 'Taking_Psychotropic'])"
      ],
      "metadata": {
        "id": "751uhdw73SfP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make X"
      ],
      "metadata": {
        "id": "lKM8p2R40XcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(chosen_X)\n",
        "data_wide = scaler.transform(chosen_X)"
      ],
      "metadata": {
        "id": "MpX2X2Vp1iWn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_wide = data_wide.reshape((-1, 7, 24, 60, 1))"
      ],
      "metadata": {
        "id": "9LIsUQyCEiNP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding function\n",
        "def pad_frames(data, new_shape):\n",
        "    padded_data = np.zeros((data.shape[0], data.shape[1], new_shape[0], new_shape[1], 1))\n",
        "    for i in range(data.shape[0]):\n",
        "        for j in range(data.shape[1]):\n",
        "            original_frame = data[i, j, :, :, 0]\n",
        "            padded_frame = np.pad(original_frame, ((0, new_shape[0] - original_frame.shape[0]), (0, new_shape[1] - original_frame.shape[1])), mode='constant', constant_values=0)\n",
        "            padded_data[i, j, :, :, 0] = padded_frame\n",
        "    return padded_data"
      ],
      "metadata": {
        "id": "sFmMbRpaIzIZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad the data\n",
        "new_shape = (60, 60)\n",
        "data_padded = pad_frames(data_wide, new_shape)\n",
        "print(\"data padded shape:\", data_padded.shape)\n",
        "print(type(data_padded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UHsOa-nI4hi",
        "outputId": "28c27f3f-f4b4-49ef-a0ea-fecc7764b488"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data padded shape: (29307, 7, 60, 60, 1)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Y"
      ],
      "metadata": {
        "id": "TJkdqzA73Wom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data Y\n",
        "Y = chosen_y\n",
        "\n",
        "# Make y array as well\n",
        "y = np.hstack(np.asarray(Y)).reshape(len(Y),1)"
      ],
      "metadata": {
        "id": "lpOo6z481iZI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(data_padded, y, test_size=0.2, stratify=y, random_state=19)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=19)\n",
        "\n",
        "\n",
        "# # Split into train, validation, and test sets\n",
        "# X_train, X_temp, y_train, y_temp = train_test_split(data_wide, y, test_size=0.2, stratify=y, random_state=19)\n",
        "# X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=19)"
      ],
      "metadata": {
        "id": "aqgvUQ2W34j0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of the data\n",
        "print(\"Shape of X_train: \", X_train.shape)\n",
        "print(\"Shape of X_val: \", X_val.shape)\n",
        "print(\"Shape of X_test: \", X_test.shape)\n",
        "\n",
        "# The shape should be (batch_size, 7, 60, 60, 1)\n",
        "\n",
        "# Class Analysis\n",
        "benzoUse = int(sum(y))\n",
        "total = int(len(y))\n",
        "benzoNoUse = int(total-benzoUse)\n",
        "\n",
        "print(\"Benzo Use:\", benzoUse, \"participants\")\n",
        "print(\"Benzo No Use:\", benzoNoUse, \"participants\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KysDBWwlx45y",
        "outputId": "eeb64aa7-517d-4ae4-8beb-25e39cb39862"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train:  (23445, 7, 60, 60, 1)\n",
            "Shape of X_val:  (2931, 7, 60, 60, 1)\n",
            "Shape of X_test:  (2931, 7, 60, 60, 1)\n",
            "Benzo Use: 694 participants\n",
            "Benzo No Use: 28613 participants\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-b9ad087e69d3>:9: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  benzoUse = int(sum(y))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"shape y_train:\", y_train.shape)\n",
        "print(\"shape y_val:\", y_val.shape)\n",
        "print(\"shape y_test:\", y_test.shape)\n",
        "\n",
        "\n",
        "# Ensure y is reshaped correctly\n",
        "y_train = y_train.reshape(-1)\n",
        "y_val = y_val.reshape(-1)\n",
        "y_test = y_test.reshape(-1)\n",
        "\n",
        "print(\"Reshaped y_train:\", y_train.shape)\n",
        "print(\"Reshaped y_val:\", y_val.shape)\n",
        "print(\"Reshaped y_test:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtQudL9jZ4dh",
        "outputId": "22863c06-81ab-475b-f25c-6ad90ba9347e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape y_train: (23445, 1)\n",
            "shape y_val: (2931, 1)\n",
            "shape y_test: (2931, 1)\n",
            "Reshaped y_train: (23445,)\n",
            "Reshaped y_val: (2931,)\n",
            "Reshaped y_test: (2931,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the ViViT Dataset"
      ],
      "metadata": {
        "id": "m9bo9QED0XeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define Dataset class with correct tensor shape\n",
        "class ActigraphyDataset(Dataset):\n",
        "    def __init__(self, X, y, transform=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = torch.tensor(self.X[idx], dtype=torch.float32)\n",
        "        X = X.permute(0, 3, 1, 2)  # Reorder dimensions to (num_frames, num_channels, height, width)\n",
        "        if self.transform:\n",
        "            X = self.transform(X)\n",
        "        return X, torch.tensor(self.y[idx], dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "rQThpoCA3-kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import transformations\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import RandomHorizontalFlip, RandomRotation\n",
        "\n",
        "# Define the augmentations with normalization\n",
        "augment = transforms.Compose([\n",
        "    RandomHorizontalFlip(),\n",
        "    RandomRotation(10),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5]),  # Normalize to range [-1, 1]\n",
        "    transforms.Lambda(lambda x: x)\n",
        "])\n",
        "\n",
        "# Apply augmentation during training\n",
        "train_dataset = ActigraphyDataset(X_train, y_train, transform=augment)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Create validation and test datasets without augmentation but with normalization\n",
        "val_dataset = ActigraphyDataset(X_val, y_val, transform=transforms.Normalize(mean=[0.5], std=[0.5]))\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "test_dataset = ActigraphyDataset(X_test, y_test, transform=transforms.Normalize(mean=[0.5], std=[0.5]))\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "8mdy1SQC4Dp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.utils.data import TensorDataset\n",
        "\n",
        "# train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
        "# val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
        "# test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))"
      ],
      "metadata": {
        "id": "J7V4QhIocT48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # data loader\n",
        "# from torch.utils.data import DataLoader\n",
        "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,num_workers=4)"
      ],
      "metadata": {
        "id": "Vx61Mc54_7p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check DataLoader shapes\n",
        "for inputs, labels in train_loader:\n",
        "    print(f\"Training - Batch inputs shape: {inputs.shape}, labels shape: {labels.shape}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZUtTS-syhHg",
        "outputId": "8ebb9d55-4c7a-42ba-9028-6bfcb3e3cfc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Batch inputs shape: torch.Size([32, 7, 1, 60, 60]), labels shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check DataLoader shapes\n",
        "for inputs, labels in val_loader:\n",
        "    print(f\"Training - Batch inputs shape: {inputs.shape}, labels shape: {labels.shape}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz3gSmdiPYYB",
        "outputId": "ce38029d-418f-4af5-8396-8cfe3ca92e72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Batch inputs shape: torch.Size([32, 7, 1, 60, 60]), labels shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check DataLoader shapes\n",
        "for inputs, labels in test_loader:\n",
        "    print(f\"Training - Batch inputs shape: {inputs.shape}, labels shape: {labels.shape}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhopm-QqPZlG",
        "outputId": "ebd9b624-6033-4f51-cc00-5968c49971a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Batch inputs shape: torch.Size([32, 7, 1, 60, 60]), labels shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "PBHfnpFu5NPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model initialization\n",
        "from transformers import VivitForVideoClassification, VivitConfig\n",
        "\n",
        "# the model configuration\n",
        "config = VivitConfig(\n",
        "    num_frames=7,\n",
        "    image_size=60,\n",
        "    patch_size=1,\n",
        "    num_channels=1,\n",
        "    num_classes=1\n",
        ")\n",
        "model = VivitForVideoClassification(config)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "ZHWeIS-x5OUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7476bf0-55e5-41f0-f12e-42c68a8046e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VivitForVideoClassification(\n",
              "  (vivit): VivitModel(\n",
              "    (embeddings): VivitEmbeddings(\n",
              "      (patch_embeddings): VivitTubeletEmbeddings(\n",
              "        (projection): Conv3d(1, 768, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
              "      )\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): VivitEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x VivitLayer(\n",
              "          (attention): VivitAttention(\n",
              "            (attention): VivitSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): VivitSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): VivitIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (intermediate_act_fn): FastGELUActivation()\n",
              "          )\n",
              "          (output): VivitOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Criterion and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "# SGD optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, weight_decay=1e-5, momentum=0.9)\n",
        "# ADAM optimizer\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5, amsgrad=True)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5, verbose=True)"
      ],
      "metadata": {
        "id": "zQVkX4tqFHoP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af6bbafe-57a6-4fba-8ff4-c8a6c240f4c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"shape of train_loader: \", len(train_loader))\n",
        "print(\"shape of val_loader: \", len(val_loader))\n",
        "print(\"shape of test_loader: \", len(test_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSxSkqDa_9si",
        "outputId": "1c533699-adc4-47b9-f4d3-70dfdcb7cf75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of train_loader:  733\n",
            "shape of val_loader:  92\n",
            "shape of test_loader:  92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Evaluation"
      ],
      "metadata": {
        "id": "E2syM0lAE27R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # IF NON-CPU\n",
        "# import torch_xla\n",
        "# import torch_xla.core.xla_model as xm\n",
        "# import torch_xla.distributed.parallel_loader as pl\n",
        "# import torch_xla.distributed.xla_multiprocessing as xmp"
      ],
      "metadata": {
        "id": "n1yhteS63lYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "GhpXwkH51Lvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # TRAINING FUNCTION WITH MIXED PRECISION\n",
        "# from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "# scaler = GradScaler()\n",
        "\n",
        "# def train(model, train_loader, val_loader, epochs=10):\n",
        "#     for epoch in range(epochs):\n",
        "#         model.train()\n",
        "#         running_loss = 0.0\n",
        "#         print(f\"Epoch {epoch+1}/{epochs} - Training\")\n",
        "#         for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "#             inputs, labels = inputs.to(device), labels.to(device).long().view(-1)\n",
        "#             optimizer.zero_grad()\n",
        "#             with autocast():\n",
        "#                 outputs = model(inputs).logits\n",
        "#                 loss = criterion(outputs, labels)\n",
        "#             scaler.scale(loss).backward()\n",
        "#             # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "#             scaler.step(optimizer)\n",
        "#             scaler.update()\n",
        "#             running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "#             if batch_idx % 100 == 0:\n",
        "#                 print(f\"Batch {batch_idx}/{len(train_loader)} - Loss: {loss.item()}\")\n",
        "\n",
        "#         epoch_loss = running_loss / len(train_loader.dataset)\n",
        "#         val_loss, val_auc = validate(model, val_loader)\n",
        "#         scheduler.step(val_loss)\n",
        "\n",
        "#         print(f\"Epoch {epoch+1}/{epochs} - Training Loss: {epoch_loss:.4f} - Validation Loss: {val_loss:.4f} - Validation AUC: {val_auc:.4f}\")"
      ],
      "metadata": {
        "id": "vq50EDJ0jyD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train function WITH EARLY STOPPING\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "scaler = GradScaler()\n",
        "\n",
        "def train(model, train_loader, val_loader, epochs=10, patience=3):\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        all_train_labels = []\n",
        "        all_train_preds = []\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Training\")\n",
        "\n",
        "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device).long().view(-1)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs).logits\n",
        "            loss = criterion(outputs, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f\"Batch {batch_idx}/{len(train_loader)} - Loss: {loss.item()}\")\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        val_loss, val_auc = validate(model, val_loader)\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Training Loss: {epoch_loss:.4f} - Validation Loss: {val_loss:.4f} - Validation AUC: {val_auc:.4f}\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping\")\n",
        "                break"
      ],
      "metadata": {
        "id": "GcT7sg1Sce-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Training function: REGULAR, WORKING, NO MIXED PRECISION\n",
        "# def train(model, train_loader, val_loader, epochs=10):\n",
        "#     for epoch in range(epochs):\n",
        "#         model.train()\n",
        "#         running_loss = 0.0\n",
        "#         print(f\"Epoch {epoch+1}/{epochs} - Training\")\n",
        "#         for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "#             inputs, labels = inputs.to(device), labels.to(device).long().view(-1)  # Flatten and convert to long\n",
        "#             optimizer.zero_grad()\n",
        "#             outputs = model(inputs).logits\n",
        "#             loss = criterion(outputs, labels)\n",
        "#             loss.backward()\n",
        "#             torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "#             optimizer.step()\n",
        "#             running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "#             if batch_idx % 100 == 0:\n",
        "#                 print(f\"Batch {batch_idx}/{len(train_loader)} - Loss: {loss.item()}\")\n",
        "\n",
        "#         epoch_loss = running_loss / len(train_loader.dataset)\n",
        "#         val_loss, val_auc = validate(model, val_loader)\n",
        "#         scheduler.step(val_loss)  # Step the learning rate scheduler\n",
        "\n",
        "#         print(f\"Epoch {epoch+1}/{epochs} - Training Loss: {epoch_loss:.4f} - Validation Loss: {val_loss:.4f} - Validation AUC: {val_auc:.4f}\")"
      ],
      "metadata": {
        "id": "fQDxAQPi1Oyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Validation function\n",
        "def validate(model, val_loader):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    print(\"Validating\")\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, labels) in enumerate(val_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device).long().view(-1)  # Flatten and convert to long\n",
        "            outputs = model(inputs).logits\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(outputs.cpu().numpy()[:, 1])\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f\"Batch {batch_idx}/{len(val_loader)} - Loss: {loss.item()}\")\n",
        "\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_preds = np.array(all_preds)\n",
        "    val_auc = roc_auc_score(all_labels, all_preds)\n",
        "    return val_loss, val_auc"
      ],
      "metadata": {
        "id": "nPJ1_-lhNa3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train(model, train_loader, val_loader, epochs=10)"
      ],
      "metadata": {
        "id": "G80Wa8Ap1TTN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "609bc859-ffb9-415c-aee1-f8df045ad9d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Training\n",
            "Batch 0/733 - Loss: 0.026047606021165848\n",
            "Batch 100/733 - Loss: 0.1262955218553543\n",
            "Batch 200/733 - Loss: 0.14741753041744232\n",
            "Batch 300/733 - Loss: 0.180332750082016\n",
            "Batch 400/733 - Loss: 0.12314686924219131\n",
            "Batch 500/733 - Loss: 0.020519452169537544\n",
            "Batch 600/733 - Loss: 0.024718986824154854\n",
            "Batch 700/733 - Loss: 0.022572048008441925\n",
            "Validating\n",
            "Batch 0/92 - Loss: 0.1264880746603012\n",
            "Batch 10/92 - Loss: 0.024618593975901604\n",
            "Batch 20/92 - Loss: 0.16227009892463684\n",
            "Batch 30/92 - Loss: 0.02083764225244522\n",
            "Batch 40/92 - Loss: 0.12674391269683838\n",
            "Batch 50/92 - Loss: 0.23148123919963837\n",
            "Batch 60/92 - Loss: 0.23262883722782135\n",
            "Batch 70/92 - Loss: 0.12475773692131042\n",
            "Batch 80/92 - Loss: 0.12978574633598328\n",
            "Batch 90/92 - Loss: 0.12648841738700867\n",
            "Epoch 1/10 - Training Loss: 0.1089 - Validation Loss: 0.1080 - Validation AUC: 0.6340\n",
            "Epoch 2/10 - Training\n",
            "Batch 0/733 - Loss: 0.3503718674182892\n",
            "Batch 100/733 - Loss: 0.02545122057199478\n",
            "Batch 200/733 - Loss: 0.17900952696800232\n",
            "Batch 300/733 - Loss: 0.028646163642406464\n",
            "Batch 400/733 - Loss: 0.02706906385719776\n",
            "Batch 500/733 - Loss: 0.12913358211517334\n",
            "Batch 600/733 - Loss: 0.2301982343196869\n",
            "Batch 700/733 - Loss: 0.025481438264250755\n",
            "Validating\n",
            "Batch 0/92 - Loss: 0.12648363411426544\n",
            "Batch 10/92 - Loss: 0.024634813889861107\n",
            "Batch 20/92 - Loss: 0.16225822269916534\n",
            "Batch 30/92 - Loss: 0.02085184119641781\n",
            "Batch 40/92 - Loss: 0.12673944234848022\n",
            "Batch 50/92 - Loss: 0.23145894706249237\n",
            "Batch 60/92 - Loss: 0.2326056808233261\n",
            "Batch 70/92 - Loss: 0.1247522234916687\n",
            "Batch 80/92 - Loss: 0.129783034324646\n",
            "Batch 90/92 - Loss: 0.1264839619398117\n",
            "Epoch 2/10 - Training Loss: 0.1089 - Validation Loss: 0.1080 - Validation AUC: 0.6340\n",
            "Epoch 3/10 - Training\n",
            "Batch 0/733 - Loss: 0.021986981853842735\n",
            "Batch 100/733 - Loss: 0.018617777153849602\n",
            "Batch 200/733 - Loss: 0.021247444674372673\n",
            "Batch 300/733 - Loss: 0.027815720066428185\n",
            "Batch 400/733 - Loss: 0.024247953668236732\n",
            "Batch 500/733 - Loss: 0.22716914117336273\n",
            "Batch 600/733 - Loss: 0.023643938824534416\n",
            "Batch 700/733 - Loss: 0.22911246120929718\n",
            "Validating\n",
            "Batch 0/92 - Loss: 0.1264788806438446\n",
            "Batch 10/92 - Loss: 0.02465115115046501\n",
            "Batch 20/92 - Loss: 0.16224759817123413\n",
            "Batch 30/92 - Loss: 0.020866170525550842\n",
            "Batch 40/92 - Loss: 0.1267346739768982\n",
            "Batch 50/92 - Loss: 0.23143644630908966\n",
            "Batch 60/92 - Loss: 0.23258203268051147\n",
            "Batch 70/92 - Loss: 0.12474631518125534\n",
            "Batch 80/92 - Loss: 0.1297801285982132\n",
            "Batch 90/92 - Loss: 0.1264791339635849\n",
            "Epoch 3/10 - Training Loss: 0.1088 - Validation Loss: 0.1080 - Validation AUC: 0.6341\n",
            "Epoch 4/10 - Training\n",
            "Batch 0/733 - Loss: 0.02520088478922844\n",
            "Batch 100/733 - Loss: 0.23788481950759888\n",
            "Batch 200/733 - Loss: 0.1289648413658142\n",
            "Batch 300/733 - Loss: 0.026336941868066788\n",
            "Batch 400/733 - Loss: 0.027997907251119614\n",
            "Batch 500/733 - Loss: 0.23090554773807526\n",
            "Batch 600/733 - Loss: 0.12960447371006012\n",
            "Batch 700/733 - Loss: 0.027502983808517456\n",
            "Validating\n",
            "Batch 0/92 - Loss: 0.1264737844467163\n",
            "Batch 10/92 - Loss: 0.024667976424098015\n",
            "Batch 20/92 - Loss: 0.16223883628845215\n",
            "Batch 30/92 - Loss: 0.020880816504359245\n",
            "Batch 40/92 - Loss: 0.12672968208789825\n",
            "Batch 50/92 - Loss: 0.2314130961894989\n",
            "Batch 60/92 - Loss: 0.23255737125873566\n",
            "Batch 70/92 - Loss: 0.12474006414413452\n",
            "Batch 80/92 - Loss: 0.12977705895900726\n",
            "Batch 90/92 - Loss: 0.1264740526676178\n",
            "Epoch 4/10 - Training Loss: 0.1089 - Validation Loss: 0.1080 - Validation AUC: 0.6340\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test function\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    print(\"Testing\")\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device).long().view(-1)\n",
        "            outputs = model(inputs).logits\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * inputs.size(0)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(outputs.cpu().numpy()[:, 1])\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f\"Batch {batch_idx}/{len(test_loader)} - Loss: {loss.item()}\")\n",
        "\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_preds = np.array(all_preds)\n",
        "    test_auc = roc_auc_score(all_labels, all_preds)\n",
        "    return test_loss, test_auc"
      ],
      "metadata": {
        "id": "b0VX5FL_ijxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_auc = test(model, test_loader)\n",
        "print(f\"Test Loss: {test_loss:.4f} - Test AUC: {test_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB0Y0SNyiocq",
        "outputId": "db92c42a-96a5-4574-f052-8050a8d00cf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing\n",
            "Batch 0/92 - Loss: 0.12826038897037506\n",
            "Batch 10/92 - Loss: 0.2490391731262207\n",
            "Batch 20/92 - Loss: 0.027544504031538963\n",
            "Batch 30/92 - Loss: 0.019538413733243942\n",
            "Batch 40/92 - Loss: 0.12825453281402588\n",
            "Batch 50/92 - Loss: 0.13108819723129272\n",
            "Batch 60/92 - Loss: 0.1287444829940796\n",
            "Batch 70/92 - Loss: 0.23502977192401886\n",
            "Batch 80/92 - Loss: 0.13039055466651917\n",
            "Batch 90/92 - Loss: 0.15979579091072083\n",
            "Test Loss: 0.1094 - Test AUC: 0.6119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.optim.lr_scheduler import CyclicLR\n",
        "\n",
        "# scheduler = CyclicLR(optimizer, base_lr=0.001, max_lr=0.01, step_size_up=2000, mode='triangular2')"
      ],
      "metadata": {
        "id": "cJHTcsAerDc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train(model, train_loader, val_loader, epochs=10)"
      ],
      "metadata": {
        "id": "kIRoEplrrx5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print Model Summary"
      ],
      "metadata": {
        "id": "W2202ums11ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj6fmLtCt1Dt",
        "outputId": "8d6b7edf-6dfe-4b06-bbb0-26e035c960f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 85,473,794 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save model weights"
      ],
      "metadata": {
        "id": "Nlyn6bL_2BQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the path where you want to save the model\n",
        "save_path = '/content/drive/MyDrive/ActigraphyTransformer/Modeling/Class Benzos/Raw Data/ViViT_Pretrained/vivit_pretrained_model_weights.pth'\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f'Model weights saved to {save_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXrqHyI42AUu",
        "outputId": "03b171a1-0c37-4211-e1d4-1e96c87b0d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights saved to /content/drive/MyDrive/ActigraphyTransformer/Modeling/Class Benzos/Raw Data/ViViT_Pretrained/vivit_pretrained_model_weights.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RvEsA15eRtA6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# VERY IMPORTANT NOTE\n",
        "# You have to connect to TPUv2 or this will NOT WORK.\n",
        "\n",
        "Go to runtime->change runtime type <br>\n",
        "Then select TPUv2 <br>\n",
        "You will need Colab Pro, but sometimes google allows anyone to connect to their TPUv2 -- give it a shot"
      ],
      "metadata": {
        "id": "gYAlnHQiUVmr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5gIiWs_BES4"
      },
      "source": [
        "# Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7IRNdjH8-rK"
      },
      "outputs": [],
      "source": [
        "# Packages\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "#from keras.layers.embeddings import Embedding\n",
        "from keras.metrics import AUC\n",
        "\n",
        "# Tf\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import random\n",
        "\n",
        "# Important Params\n",
        "n_layers = 2\n",
        "patch_length = 18"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## SEEDS\n",
        "\n",
        "# Hard Code Random Seeds.\n",
        "r1 = 0\n",
        "r2 = 1\n",
        "\n",
        "# Set Random Seed\n",
        "random.seed(r1)\n",
        "tf.random.set_seed(r2)"
      ],
      "metadata": {
        "id": "mI1HohtWRb7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Connect to TPU\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# Connect to the TPU cluster or fall back to CPU/GPU\n",
        "try:\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver()  # Tries to connect to the TPU\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  strategy = tf.distribute.TPUStrategy(resolver)\n",
        "  devices = tf.config.list_logical_devices('TPU')\n",
        "  print('TPU devices:', devices)\n",
        "except ValueError:\n",
        "  print(\"Could not connect to TPU; using CPU/GPU strategy instead.\")\n",
        "  strategy = tf.distribute.get_strategy()\n",
        "\n",
        "# Example computation using the strategy\n",
        "with strategy.scope():\n",
        "  a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "\n",
        "  @tf.function\n",
        "  def matmul_fn(x, y):\n",
        "    return tf.matmul(x, y)\n",
        "\n",
        "  z = strategy.run(matmul_fn, args=(a, b))\n",
        "\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4FiQzpNRiXw",
        "outputId": "f23c919c-dc65-41e1-a7f7-46ba56ad5277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n",
            "TPU devices: [LogicalDevice(name='/device:TPU:0', device_type='TPU'), LogicalDevice(name='/device:TPU:1', device_type='TPU'), LogicalDevice(name='/device:TPU:2', device_type='TPU'), LogicalDevice(name='/device:TPU:3', device_type='TPU'), LogicalDevice(name='/device:TPU:4', device_type='TPU'), LogicalDevice(name='/device:TPU:5', device_type='TPU'), LogicalDevice(name='/device:TPU:6', device_type='TPU'), LogicalDevice(name='/device:TPU:7', device_type='TPU')]\n",
            "PerReplica:{\n",
            "  0: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  1: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  2: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  3: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  4: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  5: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  6: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  7: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32)\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSGoEUEvA-qc"
      },
      "source": [
        "# Download Data from our Dropbox\n",
        "\n",
        "To make a dropbox link a downloadable link just change that dl=0 at the end of the link into dl=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqBb-PWN_DqC"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# Downloads any file from the internet function\n",
        "def download_file(url, filename):\n",
        "    r = requests.get(url)\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(r.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vptFzS8vADrl"
      },
      "outputs": [],
      "source": [
        "# Download X_test and y_test file from the internet\n",
        "\n",
        "####################\n",
        "# Download y_test\n",
        "####################\n",
        "\n",
        "# URL for direct download from our Google Drive\n",
        "url = 'https://www.dropbox.com/scl/fi/n9cpbawvavv3d90gg6fsw/y_test.npy?rlkey=44ltf1u0k4wltfsgryt3z5z4e&st=5vuj5amo&dl=1'\n",
        "filename = 'y_test.npy'\n",
        "\n",
        "# Download the file\n",
        "download_file(url, filename)\n",
        "\n",
        "# Load the .npy file into a numpy array\n",
        "y_test = np.load(filename)\n",
        "\n",
        "####################\n",
        "# Download X_test\n",
        "####################\n",
        "\n",
        "# URL for direct download from our Google Drive\n",
        "url = 'https://www.dropbox.com/scl/fi/nho45032np92afgpmn9o0/X_test.npy?rlkey=qyb72seovnifmlx2g2fhdyooh&st=bu1cqp45&dl=1'\n",
        "filename = 'X_test.npy'\n",
        "\n",
        "# Download the file\n",
        "download_file(url, filename)\n",
        "\n",
        "# # Load the .npy file into a numpy array\n",
        "X_test = np.load(filename)\n",
        "\n",
        "####################\n",
        "# Download Model Weights\n",
        "####################\n",
        "\n",
        "# URL for direct download from our Google Drive\n",
        "url = 'https://www.dropbox.com/scl/fi/vnc6xgc6a29gxkkcn6o3l/my_model_weights.h5?rlkey=m2mqep3ltjezfihktidw21amf&st=tmdvfm22&dl=1'\n",
        "model_weights_path = 'my_model_weights.h5'\n",
        "\n",
        "# Download the file\n",
        "download_file(url, model_weights_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7ZpytBCKe5E"
      },
      "source": [
        "https://www.dropbox.com/scl/fi/vnc6xgc6a29gxkkcn6o3l/my_model_weights.h5?rlkey=m2mqep3ltjezfihktidw21amf&st=tmdvfm22&dl=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRV51xagBRlS"
      },
      "source": [
        "# Load Pretrained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yz9LQlYJUJP"
      },
      "source": [
        "### Outline Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C572ABk9IqtO"
      },
      "outputs": [],
      "source": [
        "# Define the Transformer block\n",
        "def TransformerBlock(embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "    input_layer = tf.keras.layers.Input(shape=(None, embed_dim))\n",
        "    attention_layer = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "    attention_output, attention_weights = attention_layer(input_layer, input_layer, return_attention_scores=True)\n",
        "    attention_output = tf.keras.layers.Dropout(rate)(attention_output)\n",
        "    out1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(input_layer + attention_output)\n",
        "    ff_output = tf.keras.layers.Dense(ff_dim, activation=\"relu\")(out1)\n",
        "    ff_output = tf.keras.layers.Dense(embed_dim)(ff_output)\n",
        "    ff_output = tf.keras.layers.Dropout(rate)(ff_output)\n",
        "    final_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(out1 + ff_output)\n",
        "    return tf.keras.Model(inputs=input_layer, outputs=[final_output, attention_weights])\n",
        "\n",
        "# Define the main model\n",
        "def create_model(input_size=10080, patch_size=patch_length, embed_dim=96, num_heads=12, ff_dim=256, num_layers=n_layers, rate=0.1, training=True):\n",
        "    num_patches = input_size // patch_size\n",
        "    inputs = tf.keras.layers.Input(shape=(input_size,))\n",
        "\n",
        "    reshaped = tf.keras.layers.Reshape((num_patches, patch_size))(inputs)\n",
        "    patch_embeddings = tf.keras.layers.Dense(embed_dim)(reshaped)\n",
        "\n",
        "    positional_emb = tf.keras.layers.Embedding(input_dim=num_patches, output_dim=embed_dim)(tf.range(num_patches))\n",
        "    x = patch_embeddings + positional_emb\n",
        "\n",
        "    attention_weights = []\n",
        "\n",
        "    for _ in range(num_layers):\n",
        "        x, weights = TransformerBlock(embed_dim, num_heads, ff_dim, rate)(x)\n",
        "        if not training:\n",
        "            attention_weights.append(weights)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    x = tf.keras.layers.Dropout(rate)(x)\n",
        "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    if training:\n",
        "        return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    else:\n",
        "        return tf.keras.Model(inputs=inputs, outputs=[outputs] + attention_weights)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZSFddzJJxqx"
      },
      "source": [
        "Create the structure of the model and then change the weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkwKrnZBIytm",
        "outputId": "6a7a6bde-4c7e-45d6-b1bb-019b128a76be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 10080)]           0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 560, 18)           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 560, 96)           1824      \n",
            "                                                                 \n",
            " tf.__operators__.add (TFOp  (None, 560, 96)           0         \n",
            " Lambda)                                                         \n",
            "                                                                 \n",
            " model (Functional)          [(None, None, 96),        495808    \n",
            "                              (None, 12, None, None)             \n",
            "                             ]                                   \n",
            "                                                                 \n",
            " model_1 (Functional)        [(None, None, 96),        495808    \n",
            "                              (None, 12, None, None)             \n",
            "                             ]                                   \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 96)                0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 96)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                6208      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 999713 (3.81 MB)\n",
            "Trainable params: 999713 (3.81 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Compile the model -----\n",
        "with strategy.scope():\n",
        "  model = create_model(training=True)\n",
        "  model.compile(\n",
        "    # Metrics\n",
        "    loss= tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "    metrics= tf.keras.metrics.AUC(name='auc'),\n",
        "    # Optimizer\n",
        "    optimizer= tf.keras.optimizers.Adam(\n",
        "      learning_rate=0.00001,\n",
        "      beta_1=0.9,\n",
        "      beta_2=0.999,\n",
        "      epsilon=1e-07,\n",
        "      amsgrad=False\n",
        "))\n",
        "\n",
        "model.load_weights(model_weights_path)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izCrXsezLdwF"
      },
      "source": [
        "### Results will be displayed upon running the kernel below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbA25ziHLvqT"
      },
      "source": [
        "**Note:** You do need to use TPUv2 to get similar results. The way that the model computes changes slightly if are to use CPU, and may change the loss and auc scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SueXP1vJrfL",
        "outputId": "015d253d-1afe-44af-9284-df28eddb8407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92/92 [==============================] - 6s 31ms/step - loss: 0.7523 - auc: 0.7218\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7522586584091187, 0.7217706441879272]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model.evaluate(X_test, y_test, verbose=1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
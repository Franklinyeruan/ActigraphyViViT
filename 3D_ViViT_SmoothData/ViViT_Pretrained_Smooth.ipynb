{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ViViT Model Pretrained\n",
        "available to train with Google CPU, L4 GPU (recommended) TPUv2"
      ],
      "metadata": {
        "id": "7FaPdtq10XV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%reset -f"
      ],
      "metadata": {
        "id": "vMwD6_35DyTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Retrieve the token from Colab secrets\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "\n",
        "# Print to verify\n",
        "print(f\"HF token is: {hf_token}\")\n",
        "\n",
        "# Set the token as an environment variable\n",
        "os.environ['HUGGINGFACE_TOKEN'] = hf_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjjIaiak628b",
        "outputId": "305e13c3-d284-42ac-d3b6-560f8a7a64fc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HF token is: 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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqDy9pMy0NgP",
        "outputId": "702d6ace-77f2-4256-d9d2-d896b99223a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# write where you want to save all your files\n",
        "root = \"/content/drive/MyDrive/ActigraphyTransformer/Modeling/Class Benzos/Smoothed Data/[Smoothed]ViViT\"\n",
        "print(\"root directory is {}\".format(root))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHmOa3PV1EQg",
        "outputId": "b31a520e-bce2-45c2-cec6-c048a8b7716b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root directory is /content/drive/MyDrive/ActigraphyTransformer/Modeling/Class Benzos/Smoothed Data/[Smoothed]ViViT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Connects to TPU"
      ],
      "metadata": {
        "id": "msu8FS7P0XZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyarrow fastparquet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gffhbQVz1Z6q",
        "outputId": "9b980d45-58be-48e2-effd-677a40b0f4f7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (14.0.2)\n",
            "Collecting fastparquet\n",
            "  Downloading fastparquet-2024.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from fastparquet) (2.0.3)\n",
            "Collecting cramjam>=2.3 (from fastparquet)\n",
            "  Downloading cramjam-2.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet) (2023.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet) (24.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
            "Installing collected packages: cramjam, fastparquet\n",
            "Successfully installed cramjam-2.8.3 fastparquet-2024.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY_RMumPLx1P",
        "outputId": "f5e42078-924c-4bc2-895e-60e54f95bbd4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch pandas scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPiLuJl41e9E",
        "outputId": "5fb58285-5dbf-4e74-c4f0-cffac62c3c72"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ig_XiAx3Vn0",
        "outputId": "cbe2315c-8449-4ca7-ec60-846c48041989"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Importing\n",
        "\n",
        "# Packages\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "#from keras.layers.embeddings import Embedding\n",
        "from keras.metrics import AUC\n",
        "\n",
        "# Tf\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import random\n",
        "\n",
        "# Import Layers\n",
        "from keras.layers import ConvLSTM2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Activation\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import MaxPooling3D"
      ],
      "metadata": {
        "id": "TuoyjdvJ1iRB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## SEEDS\n",
        "\n",
        "# Hard Code Random Seeds.\n",
        "r1 = 0\n",
        "r2 = 1\n",
        "\n",
        "# Set Random Seed\n",
        "random.seed(r1)\n",
        "tf.random.set_seed(r2)"
      ],
      "metadata": {
        "id": "PMHK-lRj1jI2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the Data"
      ],
      "metadata": {
        "id": "HHvYS-C03Bek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data_all = pd.read_parquet(\"/content/drive/MyDrive/ActigraphyTransformer/Data/Actigraphy/[smoothed]WideSeqnActi_AndMeds_ALL.parq\")"
      ],
      "metadata": {
        "id": "g8gVYNX11jNN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "N5YCNZdKw_oU",
        "outputId": "4b61b633-8d9a-4a6e-c0e7-e3f5620a0b91"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Taking_SSRI  Taking_Benzodiazepine  Taking_Psychotropic  \\\n",
              "SEQN                                                               \n",
              "21005.0            0                      0                    0   \n",
              "21006.0            0                      0                    0   \n",
              "21007.0            0                      0                    0   \n",
              "21008.0            0                      0                    0   \n",
              "21009.0            0                      0                    0   \n",
              "...              ...                    ...                  ...   \n",
              "83725.0            0                      0                    0   \n",
              "83727.0            0                      0                    0   \n",
              "83729.0            0                      0                    0   \n",
              "83730.0            0                      0                    0   \n",
              "83731.0            0                      0                    0   \n",
              "\n",
              "         PAXMTSM point 1  PAXMTSM point 2  PAXMTSM point 3  PAXMTSM point 4  \\\n",
              "SEQN                                                                          \n",
              "21005.0         1.082944         1.032398         0.946086         0.828313   \n",
              "21006.0       130.992253       126.219059       121.872131       117.928978   \n",
              "21007.0        13.664286         8.583481         4.208695         0.506765   \n",
              "21008.0        19.005660        19.319370        19.894255        20.723095   \n",
              "21009.0         0.000000         0.000000         0.000000         0.000000   \n",
              "...                  ...              ...              ...              ...   \n",
              "83725.0        54.189231        54.084825        54.029946        54.019510   \n",
              "83727.0         2.600210         3.541424         4.494910         5.457441   \n",
              "83729.0         7.217905         6.387607         5.649924         5.001492   \n",
              "83730.0        49.827573        45.994585        42.520130        39.391869   \n",
              "83731.0        13.178640        12.929961        12.708204        12.511744   \n",
              "\n",
              "         PAXMTSM point 5  PAXMTSM point 6  PAXMTSM point 7  ...  \\\n",
              "SEQN                                                        ...   \n",
              "21005.0         0.683386         0.515611         0.329293  ...   \n",
              "21006.0       114.367107       111.164026       108.297243  ...   \n",
              "21007.0        -2.555475        -5.011187        -6.893537  ...   \n",
              "21008.0        21.798670        23.113759        24.661144  ...   \n",
              "21009.0         0.000000         0.000000         0.000000  ...   \n",
              "...                  ...              ...              ...  ...   \n",
              "83725.0        54.048430        54.111622        54.204000  ...   \n",
              "83727.0         6.425789         7.396726         8.367024  ...   \n",
              "83729.0         4.438947         3.958928         3.558071  ...   \n",
              "83730.0        36.597463        34.124572        31.960857  ...   \n",
              "83731.0        12.338952        12.188202        12.057866  ...   \n",
              "\n",
              "         PAXMTSM point 10071  PAXMTSM point 10072  PAXMTSM point 10073  \\\n",
              "SEQN                                                                     \n",
              "21005.0             0.000000             0.000000             0.000000   \n",
              "21006.0             0.000000             0.000000             0.000000   \n",
              "21007.0             6.393591             8.380938            10.596593   \n",
              "21008.0             0.000000             0.000000             0.000000   \n",
              "21009.0             0.000000             0.000000             0.000000   \n",
              "...                      ...                  ...                  ...   \n",
              "83725.0            26.019028            26.605473            27.175311   \n",
              "83727.0            12.366347            12.747493            13.206120   \n",
              "83729.0             0.000000             0.000000             0.000000   \n",
              "83730.0            26.993697            26.825379            26.717831   \n",
              "83731.0             8.999985             9.776766            10.784240   \n",
              "\n",
              "         PAXMTSM point 10074  PAXMTSM point 10075  PAXMTSM point 10076  \\\n",
              "SEQN                                                                     \n",
              "21005.0             0.000000             0.000000             0.000000   \n",
              "21006.0             0.000000             0.000000             0.000000   \n",
              "21007.0            13.050738            15.753558            18.715237   \n",
              "21008.0             0.000000             0.000000             0.000000   \n",
              "21009.0             0.000000             0.000000             0.000000   \n",
              "...                      ...                  ...                  ...   \n",
              "83725.0            27.724451            28.248799            28.744265   \n",
              "83727.0            13.745503            14.368912            15.079619   \n",
              "83729.0             0.000000             0.000000             0.000000   \n",
              "83730.0            26.679413            26.718489            26.843421   \n",
              "83731.0            12.036163            13.546287            15.328366   \n",
              "\n",
              "         PAXMTSM point 10077  PAXMTSM point 10078  PAXMTSM point 10079  \\\n",
              "SEQN                                                                     \n",
              "21005.0             0.000000             0.000000             0.000000   \n",
              "21006.0             0.000000             0.000000             0.000000   \n",
              "21007.0            21.945958            25.455906            29.255264   \n",
              "21008.0             0.000000             0.000000             0.000000   \n",
              "21009.0             0.000000             0.000000             0.000000   \n",
              "...                      ...                  ...                  ...   \n",
              "83725.0            29.206756            29.632180            30.016446   \n",
              "83727.0            15.880896            16.776016            17.768250   \n",
              "83729.0             0.000000             0.000000             0.000000   \n",
              "83730.0            27.062570            27.384300            27.816972   \n",
              "83731.0            17.396155            19.763407            22.443876   \n",
              "\n",
              "         PAXMTSM point 10080  \n",
              "SEQN                          \n",
              "21005.0             0.000000  \n",
              "21006.0             0.000000  \n",
              "21007.0            33.354215  \n",
              "21008.0             0.000000  \n",
              "21009.0             0.000000  \n",
              "...                      ...  \n",
              "83725.0            30.355461  \n",
              "83727.0            18.860870  \n",
              "83729.0             0.000000  \n",
              "83730.0            28.368949  \n",
              "83731.0            25.451316  \n",
              "\n",
              "[29307 rows x 10083 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6288bc48-5514-4cb0-966a-ee099e6a6f67\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Taking_SSRI</th>\n",
              "      <th>Taking_Benzodiazepine</th>\n",
              "      <th>Taking_Psychotropic</th>\n",
              "      <th>PAXMTSM point 1</th>\n",
              "      <th>PAXMTSM point 2</th>\n",
              "      <th>PAXMTSM point 3</th>\n",
              "      <th>PAXMTSM point 4</th>\n",
              "      <th>PAXMTSM point 5</th>\n",
              "      <th>PAXMTSM point 6</th>\n",
              "      <th>PAXMTSM point 7</th>\n",
              "      <th>...</th>\n",
              "      <th>PAXMTSM point 10071</th>\n",
              "      <th>PAXMTSM point 10072</th>\n",
              "      <th>PAXMTSM point 10073</th>\n",
              "      <th>PAXMTSM point 10074</th>\n",
              "      <th>PAXMTSM point 10075</th>\n",
              "      <th>PAXMTSM point 10076</th>\n",
              "      <th>PAXMTSM point 10077</th>\n",
              "      <th>PAXMTSM point 10078</th>\n",
              "      <th>PAXMTSM point 10079</th>\n",
              "      <th>PAXMTSM point 10080</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SEQN</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21005.0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.082944</td>\n",
              "      <td>1.032398</td>\n",
              "      <td>0.946086</td>\n",
              "      <td>0.828313</td>\n",
              "      <td>0.683386</td>\n",
              "      <td>0.515611</td>\n",
              "      <td>0.329293</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21006.0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>130.992253</td>\n",
              "      <td>126.219059</td>\n",
              "      <td>121.872131</td>\n",
              "      <td>117.928978</td>\n",
              "      <td>114.367107</td>\n",
              "      <td>111.164026</td>\n",
              "      <td>108.297243</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21007.0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.664286</td>\n",
              "      <td>8.583481</td>\n",
              "      <td>4.208695</td>\n",
              "      <td>0.506765</td>\n",
              "      <td>-2.555475</td>\n",
              "      <td>-5.011187</td>\n",
              "      <td>-6.893537</td>\n",
              "      <td>...</td>\n",
              "      <td>6.393591</td>\n",
              "      <td>8.380938</td>\n",
              "      <td>10.596593</td>\n",
              "      <td>13.050738</td>\n",
              "      <td>15.753558</td>\n",
              "      <td>18.715237</td>\n",
              "      <td>21.945958</td>\n",
              "      <td>25.455906</td>\n",
              "      <td>29.255264</td>\n",
              "      <td>33.354215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21008.0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19.005660</td>\n",
              "      <td>19.319370</td>\n",
              "      <td>19.894255</td>\n",
              "      <td>20.723095</td>\n",
              "      <td>21.798670</td>\n",
              "      <td>23.113759</td>\n",
              "      <td>24.661144</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21009.0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83725.0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>54.189231</td>\n",
              "      <td>54.084825</td>\n",
              "      <td>54.029946</td>\n",
              "      <td>54.019510</td>\n",
              "      <td>54.048430</td>\n",
              "      <td>54.111622</td>\n",
              "      <td>54.204000</td>\n",
              "      <td>...</td>\n",
              "      <td>26.019028</td>\n",
              "      <td>26.605473</td>\n",
              "      <td>27.175311</td>\n",
              "      <td>27.724451</td>\n",
              "      <td>28.248799</td>\n",
              "      <td>28.744265</td>\n",
              "      <td>29.206756</td>\n",
              "      <td>29.632180</td>\n",
              "      <td>30.016446</td>\n",
              "      <td>30.355461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83727.0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.600210</td>\n",
              "      <td>3.541424</td>\n",
              "      <td>4.494910</td>\n",
              "      <td>5.457441</td>\n",
              "      <td>6.425789</td>\n",
              "      <td>7.396726</td>\n",
              "      <td>8.367024</td>\n",
              "      <td>...</td>\n",
              "      <td>12.366347</td>\n",
              "      <td>12.747493</td>\n",
              "      <td>13.206120</td>\n",
              "      <td>13.745503</td>\n",
              "      <td>14.368912</td>\n",
              "      <td>15.079619</td>\n",
              "      <td>15.880896</td>\n",
              "      <td>16.776016</td>\n",
              "      <td>17.768250</td>\n",
              "      <td>18.860870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83729.0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.217905</td>\n",
              "      <td>6.387607</td>\n",
              "      <td>5.649924</td>\n",
              "      <td>5.001492</td>\n",
              "      <td>4.438947</td>\n",
              "      <td>3.958928</td>\n",
              "      <td>3.558071</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83730.0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>49.827573</td>\n",
              "      <td>45.994585</td>\n",
              "      <td>42.520130</td>\n",
              "      <td>39.391869</td>\n",
              "      <td>36.597463</td>\n",
              "      <td>34.124572</td>\n",
              "      <td>31.960857</td>\n",
              "      <td>...</td>\n",
              "      <td>26.993697</td>\n",
              "      <td>26.825379</td>\n",
              "      <td>26.717831</td>\n",
              "      <td>26.679413</td>\n",
              "      <td>26.718489</td>\n",
              "      <td>26.843421</td>\n",
              "      <td>27.062570</td>\n",
              "      <td>27.384300</td>\n",
              "      <td>27.816972</td>\n",
              "      <td>28.368949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83731.0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.178640</td>\n",
              "      <td>12.929961</td>\n",
              "      <td>12.708204</td>\n",
              "      <td>12.511744</td>\n",
              "      <td>12.338952</td>\n",
              "      <td>12.188202</td>\n",
              "      <td>12.057866</td>\n",
              "      <td>...</td>\n",
              "      <td>8.999985</td>\n",
              "      <td>9.776766</td>\n",
              "      <td>10.784240</td>\n",
              "      <td>12.036163</td>\n",
              "      <td>13.546287</td>\n",
              "      <td>15.328366</td>\n",
              "      <td>17.396155</td>\n",
              "      <td>19.763407</td>\n",
              "      <td>22.443876</td>\n",
              "      <td>25.451316</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29307 rows × 10083 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6288bc48-5514-4cb0-966a-ee099e6a6f67')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6288bc48-5514-4cb0-966a-ee099e6a6f67 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6288bc48-5514-4cb0-966a-ee099e6a6f67');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-be0fddca-3ee7-4a7d-a8ff-2261608c446d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-be0fddca-3ee7-4a7d-a8ff-2261608c446d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-be0fddca-3ee7-4a7d-a8ff-2261608c446d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b331ba81-16f5-43fb-b9fa-48caae5f04f5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data_all')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b331ba81-16f5-43fb-b9fa-48caae5f04f5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data_all');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_all"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Choose Variable"
      ],
      "metadata": {
        "id": "AV-IS4a63M5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Spit actigraphy X and then y\n",
        "chosen_y = data_all['Taking_Benzodiazepine']\n",
        "chosen_X = data_all.drop(columns=['Taking_SSRI', 'Taking_Benzodiazepine', 'Taking_Psychotropic'])"
      ],
      "metadata": {
        "id": "751uhdw73SfP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make X"
      ],
      "metadata": {
        "id": "lKM8p2R40XcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(chosen_X)\n",
        "data_wide = scaler.transform(chosen_X)"
      ],
      "metadata": {
        "id": "MpX2X2Vp1iWn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_wide = data_wide.reshape((-1, 7, 24, 60, 1))"
      ],
      "metadata": {
        "id": "9LIsUQyCEiNP"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding function\n",
        "def pad_frames(data, new_shape):\n",
        "    padded_data = np.zeros((data.shape[0], data.shape[1], new_shape[0], new_shape[1], 1))\n",
        "    for i in range(data.shape[0]):\n",
        "        for j in range(data.shape[1]):\n",
        "            original_frame = data[i, j, :, :, 0]\n",
        "            padded_frame = np.pad(original_frame, ((0, new_shape[0] - original_frame.shape[0]), (0, new_shape[1] - original_frame.shape[1])), mode='constant', constant_values=0)\n",
        "            padded_data[i, j, :, :, 0] = padded_frame\n",
        "    return padded_data"
      ],
      "metadata": {
        "id": "sFmMbRpaIzIZ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad the data\n",
        "new_shape = (60, 60)\n",
        "data_padded = pad_frames(data_wide, new_shape)\n",
        "print(\"data padded shape:\", data_padded.shape)\n",
        "print(type(data_padded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UHsOa-nI4hi",
        "outputId": "ed06c20f-6ca6-4dc7-8c0e-9f36299884da"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data padded shape: (29307, 7, 60, 60, 1)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Y"
      ],
      "metadata": {
        "id": "TJkdqzA73Wom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data Y\n",
        "Y = chosen_y\n",
        "\n",
        "# Make y array as well\n",
        "y = np.hstack(np.asarray(Y)).reshape(len(Y),1)"
      ],
      "metadata": {
        "id": "lpOo6z481iZI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(data_padded, y, test_size=0.2, stratify=y, random_state=19)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=19)\n",
        "\n",
        "\n",
        "# # Split into train, validation, and test sets\n",
        "# X_train, X_temp, y_train, y_temp = train_test_split(data_wide, y, test_size=0.2, stratify=y, random_state=19)\n",
        "# X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=19)"
      ],
      "metadata": {
        "id": "aqgvUQ2W34j0"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zS5GVzNfQd5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of the data\n",
        "print(\"Shape of X_train: \", X_train.shape)\n",
        "print(\"Shape of X_val: \", X_val.shape)\n",
        "print(\"Shape of X_test: \", X_test.shape)\n",
        "\n",
        "# The shape should be (batch_size, 7, 60, 60, 1)\n",
        "\n",
        "# Class Analysis\n",
        "benzoUse = int(sum(y))\n",
        "total = int(len(y))\n",
        "benzoNoUse = int(total-benzoUse)\n",
        "\n",
        "print(\"Benzo Use:\", benzoUse, \"participants\")\n",
        "print(\"Benzo No Use:\", benzoNoUse, \"participants\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KysDBWwlx45y",
        "outputId": "2623a022-b28d-4273-aaee-cf1c3518bd25"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train:  (23445, 7, 60, 60, 1)\n",
            "Shape of X_val:  (2931, 7, 60, 60, 1)\n",
            "Shape of X_test:  (2931, 7, 60, 60, 1)\n",
            "Benzo Use: 694 participants\n",
            "Benzo No Use: 28613 participants\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-b9ad087e69d3>:9: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  benzoUse = int(sum(y))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"shape y_train:\", y_train.shape)\n",
        "print(\"shape y_val:\", y_val.shape)\n",
        "print(\"shape y_test:\", y_test.shape)\n",
        "\n",
        "\n",
        "# Ensure y is reshaped correctly\n",
        "y_train = y_train.reshape(-1)\n",
        "y_val = y_val.reshape(-1)\n",
        "y_test = y_test.reshape(-1)\n",
        "\n",
        "print(\"Reshaped y_train:\", y_train.shape)\n",
        "print(\"Reshaped y_val:\", y_val.shape)\n",
        "print(\"Reshaped y_test:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtQudL9jZ4dh",
        "outputId": "fe56f9dd-decc-4439-dbeb-5ae50f6e3b03"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape y_train: (23445, 1)\n",
            "shape y_val: (2931, 1)\n",
            "shape y_test: (2931, 1)\n",
            "Reshaped y_train: (23445,)\n",
            "Reshaped y_val: (2931,)\n",
            "Reshaped y_test: (2931,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the ViViT Dataset"
      ],
      "metadata": {
        "id": "m9bo9QED0XeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define Dataset class with correct tensor shape\n",
        "class ActigraphyDataset(Dataset):\n",
        "    def __init__(self, X, y, transform=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = torch.tensor(self.X[idx], dtype=torch.float32)\n",
        "        X = X.permute(0, 3, 1, 2)  # Reorder dimensions to (num_frames, num_channels, height, width)\n",
        "        if self.transform:\n",
        "            X = self.transform(X)\n",
        "        return X, torch.tensor(self.y[idx], dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "rQThpoCA3-kE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import transformations\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import RandomHorizontalFlip, RandomRotation\n",
        "\n",
        "# Define the augmentations with normalization\n",
        "augment = transforms.Compose([\n",
        "    RandomHorizontalFlip(),\n",
        "    RandomRotation(10),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5]),  # Normalize to range [-1, 1]\n",
        "    transforms.Lambda(lambda x: x)\n",
        "])\n",
        "\n",
        "# Apply augmentation during training\n",
        "train_dataset = ActigraphyDataset(X_train, y_train, transform=augment)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Create validation and test datasets without augmentation but with normalization\n",
        "val_dataset = ActigraphyDataset(X_val, y_val, transform=transforms.Normalize(mean=[0.5], std=[0.5]))\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "test_dataset = ActigraphyDataset(X_test, y_test, transform=transforms.Normalize(mean=[0.5], std=[0.5]))\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "8mdy1SQC4Dp1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.utils.data import TensorDataset\n",
        "\n",
        "# train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
        "# val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
        "# test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))"
      ],
      "metadata": {
        "id": "J7V4QhIocT48"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # data loader\n",
        "# from torch.utils.data import DataLoader\n",
        "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,num_workers=4)"
      ],
      "metadata": {
        "id": "Vx61Mc54_7p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check DataLoader shapes\n",
        "for inputs, labels in train_loader:\n",
        "    print(f\"Training - Batch inputs shape: {inputs.shape}, labels shape: {labels.shape}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZUtTS-syhHg",
        "outputId": "d054170f-4cd5-494b-f6df-9f1e41898900"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Batch inputs shape: torch.Size([32, 7, 1, 60, 60]), labels shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check DataLoader shapes\n",
        "for inputs, labels in val_loader:\n",
        "    print(f\"Training - Batch inputs shape: {inputs.shape}, labels shape: {labels.shape}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz3gSmdiPYYB",
        "outputId": "6a6f35ef-a226-40a4-c443-f9543ae8e42a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Batch inputs shape: torch.Size([32, 7, 1, 60, 60]), labels shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check DataLoader shapes\n",
        "for inputs, labels in test_loader:\n",
        "    print(f\"Training - Batch inputs shape: {inputs.shape}, labels shape: {labels.shape}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhopm-QqPZlG",
        "outputId": "8440058b-b88b-416f-b85b-bec1ce93d0b2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Batch inputs shape: torch.Size([32, 7, 1, 60, 60]), labels shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "PBHfnpFu5NPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model initialization\n",
        "from transformers import VivitForVideoClassification, VivitConfig\n",
        "\n",
        "# the model configuration\n",
        "config = VivitConfig(\n",
        "    num_frames=7,\n",
        "    image_size=60,\n",
        "    patch_size=1,\n",
        "    num_channels=1,\n",
        "    num_classes=1\n",
        ")\n",
        "model = VivitForVideoClassification(config)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "ZHWeIS-x5OUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c50f1803-516f-4ee7-a742-a2ed770faa80"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VivitForVideoClassification(\n",
              "  (vivit): VivitModel(\n",
              "    (embeddings): VivitEmbeddings(\n",
              "      (patch_embeddings): VivitTubeletEmbeddings(\n",
              "        (projection): Conv3d(1, 768, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
              "      )\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): VivitEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x VivitLayer(\n",
              "          (attention): VivitAttention(\n",
              "            (attention): VivitSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): VivitSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): VivitIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (intermediate_act_fn): FastGELUActivation()\n",
              "          )\n",
              "          (output): VivitOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Criterion and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "# SGD optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, weight_decay=1e-5, momentum=0.9)\n",
        "# ADAM optimizer\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5, amsgrad=True)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5, verbose=True)"
      ],
      "metadata": {
        "id": "zQVkX4tqFHoP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "694f24bb-b9be-4391-8fa1-3ee2b0de2cf4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"shape of train_loader: \", len(train_loader))\n",
        "print(\"shape of val_loader: \", len(val_loader))\n",
        "print(\"shape of test_loader: \", len(test_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSxSkqDa_9si",
        "outputId": "ac6a7245-4900-4f50-a12e-a245fd81b50b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of train_loader:  733\n",
            "shape of val_loader:  92\n",
            "shape of test_loader:  92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Evaluation"
      ],
      "metadata": {
        "id": "E2syM0lAE27R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train function WITH EARLY STOPPING\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "scaler = GradScaler()\n",
        "\n",
        "def train(model, train_loader, val_loader, epochs=10, patience=3):\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        all_train_labels = []\n",
        "        all_train_preds = []\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Training\")\n",
        "\n",
        "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device).long().view(-1)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs).logits\n",
        "            loss = criterion(outputs, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f\"Batch {batch_idx}/{len(train_loader)} - Loss: {loss.item()}\")\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        val_loss, val_auc = validate(model, val_loader)\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Training Loss: {epoch_loss:.4f} - Validation Loss: {val_loss:.4f} - Validation AUC: {val_auc:.4f}\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping\")\n",
        "                break"
      ],
      "metadata": {
        "id": "GcT7sg1Sce-R"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Training function: REGULAR, WORKING, NO MIXED PRECISION\n",
        "# def train(model, train_loader, val_loader, epochs=10):\n",
        "#     for epoch in range(epochs):\n",
        "#         model.train()\n",
        "#         running_loss = 0.0\n",
        "#         print(f\"Epoch {epoch+1}/{epochs} - Training\")\n",
        "#         for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "#             inputs, labels = inputs.to(device), labels.to(device).long().view(-1)  # Flatten and convert to long\n",
        "#             optimizer.zero_grad()\n",
        "#             outputs = model(inputs).logits\n",
        "#             loss = criterion(outputs, labels)\n",
        "#             loss.backward()\n",
        "#             torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "#             optimizer.step()\n",
        "#             running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "#             if batch_idx % 100 == 0:\n",
        "#                 print(f\"Batch {batch_idx}/{len(train_loader)} - Loss: {loss.item()}\")\n",
        "\n",
        "#         epoch_loss = running_loss / len(train_loader.dataset)\n",
        "#         val_loss, val_auc = validate(model, val_loader)\n",
        "#         scheduler.step(val_loss)  # Step the learning rate scheduler\n",
        "\n",
        "#         print(f\"Epoch {epoch+1}/{epochs} - Training Loss: {epoch_loss:.4f} - Validation Loss: {val_loss:.4f} - Validation AUC: {val_auc:.4f}\")"
      ],
      "metadata": {
        "id": "fQDxAQPi1Oyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Validation function\n",
        "def validate(model, val_loader):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    print(\"Validating\")\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, labels) in enumerate(val_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device).long().view(-1)  # Flatten and convert to long\n",
        "            outputs = model(inputs).logits\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(outputs.cpu().numpy()[:, 1])\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f\"Batch {batch_idx}/{len(val_loader)} - Loss: {loss.item()}\")\n",
        "\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_preds = np.array(all_preds)\n",
        "    val_auc = roc_auc_score(all_labels, all_preds)\n",
        "    return val_loss, val_auc"
      ],
      "metadata": {
        "id": "nPJ1_-lhNa3X"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train(model, train_loader, val_loader, epochs=10)"
      ],
      "metadata": {
        "id": "G80Wa8Ap1TTN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d47d292-5cc7-4b4c-aedf-1068bb7e3c65"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Training\n",
            "Batch 0/733 - Loss: 0.9308729767799377\n",
            "Batch 100/733 - Loss: 0.936718225479126\n",
            "Batch 200/733 - Loss: 0.9447352290153503\n",
            "Batch 300/733 - Loss: 0.9455954432487488\n",
            "Batch 400/733 - Loss: 0.943016529083252\n",
            "Batch 500/733 - Loss: 0.9263385534286499\n",
            "Batch 600/733 - Loss: 0.923657238483429\n",
            "Batch 700/733 - Loss: 0.9224522709846497\n",
            "Validating\n",
            "Batch 0/92 - Loss: 0.9002339839935303\n",
            "Batch 10/92 - Loss: 0.9397218227386475\n",
            "Batch 20/92 - Loss: 0.9313400387763977\n",
            "Batch 30/92 - Loss: 0.9357959628105164\n",
            "Batch 40/92 - Loss: 0.9239423274993896\n",
            "Batch 50/92 - Loss: 0.9053254723548889\n",
            "Batch 60/92 - Loss: 0.8910431861877441\n",
            "Batch 70/92 - Loss: 0.9234088659286499\n",
            "Batch 80/92 - Loss: 0.9131529927253723\n",
            "Batch 90/92 - Loss: 0.9186663627624512\n",
            "Epoch 1/10 - Training Loss: 0.9245 - Validation Loss: 0.9194 - Validation AUC: 0.4291\n",
            "Epoch 2/10 - Training\n",
            "Batch 0/733 - Loss: 0.9307625889778137\n",
            "Batch 100/733 - Loss: 0.9308173060417175\n",
            "Batch 200/733 - Loss: 0.9193366765975952\n",
            "Batch 300/733 - Loss: 0.9167290329933167\n",
            "Batch 400/733 - Loss: 0.9034602046012878\n",
            "Batch 500/733 - Loss: 0.9143090844154358\n",
            "Batch 600/733 - Loss: 0.9029591679573059\n",
            "Batch 700/733 - Loss: 0.9044355750083923\n",
            "Validating\n",
            "Batch 0/92 - Loss: 0.8932034373283386\n",
            "Batch 10/92 - Loss: 0.932192325592041\n",
            "Batch 20/92 - Loss: 0.9243156909942627\n",
            "Batch 30/92 - Loss: 0.9282739758491516\n",
            "Batch 40/92 - Loss: 0.9167738556861877\n",
            "Batch 50/92 - Loss: 0.8986125588417053\n",
            "Batch 60/92 - Loss: 0.8845602869987488\n",
            "Batch 70/92 - Loss: 0.9163618683815002\n",
            "Batch 80/92 - Loss: 0.9060825109481812\n",
            "Batch 90/92 - Loss: 0.9115447998046875\n",
            "Epoch 2/10 - Training Loss: 0.9174 - Validation Loss: 0.9122 - Validation AUC: 0.4290\n",
            "Epoch 3/10 - Training\n",
            "Batch 0/733 - Loss: 0.9274550080299377\n",
            "Batch 100/733 - Loss: 0.9107148051261902\n",
            "Batch 200/733 - Loss: 0.8908458948135376\n",
            "Batch 300/733 - Loss: 0.9126605987548828\n",
            "Batch 400/733 - Loss: 0.9101632833480835\n",
            "Batch 500/733 - Loss: 0.9047423601150513\n",
            "Batch 600/733 - Loss: 0.9083440899848938\n",
            "Batch 700/733 - Loss: 0.919585645198822\n",
            "Validating\n",
            "Batch 0/92 - Loss: 0.8872338533401489\n",
            "Batch 10/92 - Loss: 0.9257895350456238\n",
            "Batch 20/92 - Loss: 0.918334424495697\n",
            "Batch 30/92 - Loss: 0.9218833446502686\n",
            "Batch 40/92 - Loss: 0.9106829166412354\n",
            "Batch 50/92 - Loss: 0.8929130434989929\n",
            "Batch 60/92 - Loss: 0.8790547251701355\n",
            "Batch 70/92 - Loss: 0.9103685021400452\n",
            "Batch 80/92 - Loss: 0.9000773429870605\n",
            "Batch 90/92 - Loss: 0.9054928421974182\n",
            "Epoch 3/10 - Training Loss: 0.9103 - Validation Loss: 0.9061 - Validation AUC: 0.4290\n",
            "Epoch 4/10 - Training\n",
            "Batch 0/733 - Loss: 0.9065122008323669\n",
            "Batch 100/733 - Loss: 0.9015418291091919\n",
            "Batch 200/733 - Loss: 0.8995479941368103\n",
            "Batch 300/733 - Loss: 0.903352677822113\n",
            "Batch 400/733 - Loss: 0.8931818008422852\n",
            "Batch 500/733 - Loss: 0.9030932784080505\n",
            "Batch 600/733 - Loss: 0.9258313775062561\n",
            "Batch 700/733 - Loss: 0.8933973908424377\n",
            "Validating\n",
            "Batch 0/92 - Loss: 0.8837748765945435\n",
            "Batch 10/92 - Loss: 0.9220795035362244\n",
            "Batch 20/92 - Loss: 0.9148820042610168\n",
            "Batch 30/92 - Loss: 0.9181738495826721\n",
            "Batch 40/92 - Loss: 0.907151460647583\n",
            "Batch 50/92 - Loss: 0.8896074891090393\n",
            "Batch 60/92 - Loss: 0.8758671879768372\n",
            "Batch 70/92 - Loss: 0.9069074392318726\n",
            "Batch 80/92 - Loss: 0.8965939879417419\n",
            "Batch 90/92 - Loss: 0.9019820690155029\n",
            "Epoch 4/10 - Training Loss: 0.9058 - Validation Loss: 0.9026 - Validation AUC: 0.4290\n",
            "Epoch 5/10 - Training\n",
            "Batch 0/733 - Loss: 0.892587423324585\n",
            "Batch 100/733 - Loss: 0.9037506580352783\n",
            "Batch 200/733 - Loss: 0.9097452759742737\n",
            "Batch 300/733 - Loss: 0.9221035242080688\n",
            "Batch 400/733 - Loss: 0.9117139577865601\n",
            "Batch 500/733 - Loss: 0.9072494506835938\n",
            "Batch 600/733 - Loss: 0.9021673798561096\n",
            "Batch 700/733 - Loss: 0.9076524376869202\n",
            "Validating\n",
            "Batch 0/92 - Loss: 0.880149781703949\n",
            "Batch 10/92 - Loss: 0.9181975722312927\n",
            "Batch 20/92 - Loss: 0.9112547636032104\n",
            "Batch 30/92 - Loss: 0.9142897725105286\n",
            "Batch 40/92 - Loss: 0.9034520983695984\n",
            "Batch 50/92 - Loss: 0.8861464858055115\n",
            "Batch 60/92 - Loss: 0.8725262880325317\n",
            "Batch 70/92 - Loss: 0.9032819271087646\n",
            "Batch 80/92 - Loss: 0.8929444551467896\n",
            "Batch 90/92 - Loss: 0.898306667804718\n",
            "Epoch 5/10 - Training Loss: 0.9021 - Validation Loss: 0.8989 - Validation AUC: 0.4290\n",
            "Epoch 6/10 - Training\n",
            "Batch 0/733 - Loss: 0.8900935053825378\n",
            "Batch 100/733 - Loss: 0.897440493106842\n",
            "Batch 200/733 - Loss: 0.8910553455352783\n",
            "Batch 300/733 - Loss: 0.9082139134407043\n",
            "Batch 400/733 - Loss: 0.9279640913009644\n",
            "Batch 500/733 - Loss: 0.9150049686431885\n",
            "Batch 600/733 - Loss: 0.9028764367103577\n",
            "Batch 700/733 - Loss: 0.8945242166519165\n",
            "Validating\n",
            "Batch 0/92 - Loss: 0.877589225769043\n",
            "Batch 10/92 - Loss: 0.9154472947120667\n",
            "Batch 20/92 - Loss: 0.9086896181106567\n",
            "Batch 30/92 - Loss: 0.9115448594093323\n",
            "Batch 40/92 - Loss: 0.9008369445800781\n",
            "Batch 50/92 - Loss: 0.8836998343467712\n",
            "Batch 60/92 - Loss: 0.8701684474945068\n",
            "Batch 70/92 - Loss: 0.9007052779197693\n",
            "Batch 80/92 - Loss: 0.8903678059577942\n",
            "Batch 90/92 - Loss: 0.8957086801528931\n",
            "Epoch 6/10 - Training Loss: 0.8988 - Validation Loss: 0.8962 - Validation AUC: 0.4291\n",
            "Epoch 7/10 - Training\n",
            "Batch 0/733 - Loss: 0.8880853652954102\n",
            "Batch 100/733 - Loss: 0.8880162835121155\n",
            "Batch 200/733 - Loss: 0.8943959474563599\n",
            "Batch 300/733 - Loss: 0.8926389813423157\n",
            "Batch 400/733 - Loss: 0.9040517807006836\n",
            "Batch 500/733 - Loss: 0.8890215158462524\n",
            "Batch 600/733 - Loss: 0.9031538963317871\n",
            "Batch 700/733 - Loss: 0.9012126326560974\n",
            "Validating\n",
            "Batch 0/92 - Loss: 0.8759897351264954\n",
            "Batch 10/92 - Loss: 0.9137220978736877\n",
            "Batch 20/92 - Loss: 0.9070754647254944\n",
            "Batch 30/92 - Loss: 0.9098256826400757\n",
            "Batch 40/92 - Loss: 0.8992004990577698\n",
            "Batch 50/92 - Loss: 0.8821685314178467\n",
            "Batch 60/92 - Loss: 0.8686903715133667\n",
            "Batch 70/92 - Loss: 0.8990908265113831\n",
            "Batch 80/92 - Loss: 0.8887569308280945\n",
            "Batch 90/92 - Loss: 0.8940848708152771\n",
            "Epoch 7/10 - Training Loss: 0.8969 - Validation Loss: 0.8946 - Validation AUC: 0.4290\n",
            "Epoch 8/10 - Training\n",
            "Batch 0/733 - Loss: 0.9013136625289917\n",
            "Batch 100/733 - Loss: 0.9107995629310608\n",
            "Batch 200/733 - Loss: 0.9008434414863586\n",
            "Batch 300/733 - Loss: 0.8538194894790649\n",
            "Batch 400/733 - Loss: 0.9135646820068359\n",
            "Batch 500/733 - Loss: 0.8930224776268005\n",
            "Batch 600/733 - Loss: 0.8925104737281799\n",
            "Batch 700/733 - Loss: 0.8768337368965149\n",
            "Validating\n",
            "Batch 0/92 - Loss: 0.874201238155365\n",
            "Batch 10/92 - Loss: 0.911803126335144\n",
            "Batch 20/92 - Loss: 0.9052799940109253\n",
            "Batch 30/92 - Loss: 0.9079082608222961\n",
            "Batch 40/92 - Loss: 0.8973761796951294\n",
            "Batch 50/92 - Loss: 0.8804624080657959\n",
            "Batch 60/92 - Loss: 0.8670404553413391\n",
            "Batch 70/92 - Loss: 0.8972945809364319\n",
            "Batch 80/92 - Loss: 0.8869604468345642\n",
            "Batch 90/92 - Loss: 0.8922731280326843\n",
            "Epoch 8/10 - Training Loss: 0.8951 - Validation Loss: 0.8928 - Validation AUC: 0.4290\n",
            "Epoch 9/10 - Training\n",
            "Batch 0/733 - Loss: 0.8925293684005737\n",
            "Batch 100/733 - Loss: 0.9165777564048767\n",
            "Batch 200/733 - Loss: 0.8947930932044983\n",
            "Batch 300/733 - Loss: 0.8714964389801025\n",
            "Batch 400/733 - Loss: 0.8562984466552734\n",
            "Batch 500/733 - Loss: 0.8869507312774658\n",
            "Batch 600/733 - Loss: 0.9062931537628174\n",
            "Batch 700/733 - Loss: 0.8690026998519897\n",
            "Validating\n",
            "Batch 0/92 - Loss: 0.8733571171760559\n",
            "Batch 10/92 - Loss: 0.9108905792236328\n",
            "Batch 20/92 - Loss: 0.9044253826141357\n",
            "Batch 30/92 - Loss: 0.9070019125938416\n",
            "Batch 40/92 - Loss: 0.8965113759040833\n",
            "Batch 50/92 - Loss: 0.87965327501297\n",
            "Batch 60/92 - Loss: 0.8662548661231995\n",
            "Batch 70/92 - Loss: 0.8964421153068542\n",
            "Batch 80/92 - Loss: 0.8861072659492493\n",
            "Batch 90/92 - Loss: 0.8914135694503784\n",
            "Epoch 9/10 - Training Loss: 0.8936 - Validation Loss: 0.8919 - Validation AUC: 0.4290\n",
            "Epoch 10/10 - Training\n",
            "Batch 0/733 - Loss: 0.8665789365768433\n",
            "Batch 100/733 - Loss: 0.8984986543655396\n",
            "Batch 200/733 - Loss: 0.8772927522659302\n",
            "Batch 300/733 - Loss: 0.8942016959190369\n",
            "Batch 400/733 - Loss: 0.8987671732902527\n",
            "Batch 500/733 - Loss: 0.8838048577308655\n",
            "Batch 600/733 - Loss: 0.9094383120536804\n",
            "Batch 700/733 - Loss: 0.895099937915802\n",
            "Validating\n",
            "Batch 0/92 - Loss: 0.8725742697715759\n",
            "Batch 10/92 - Loss: 0.9100510478019714\n",
            "Batch 20/92 - Loss: 0.9036422967910767\n",
            "Batch 30/92 - Loss: 0.9061591029167175\n",
            "Batch 40/92 - Loss: 0.8957120180130005\n",
            "Batch 50/92 - Loss: 0.8789059519767761\n",
            "Batch 60/92 - Loss: 0.8655292987823486\n",
            "Batch 70/92 - Loss: 0.895660400390625\n",
            "Batch 80/92 - Loss: 0.8853182792663574\n",
            "Batch 90/92 - Loss: 0.8906171917915344\n",
            "Epoch 10/10 - Training Loss: 0.8928 - Validation Loss: 0.8911 - Validation AUC: 0.4289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test function\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    print(\"Testing\")\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device).long().view(-1)\n",
        "            outputs = model(inputs).logits\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * inputs.size(0)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(outputs.cpu().numpy()[:, 1])\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f\"Batch {batch_idx}/{len(test_loader)} - Loss: {loss.item()}\")\n",
        "\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_preds = np.array(all_preds)\n",
        "    test_auc = roc_auc_score(all_labels, all_preds)\n",
        "    return test_loss, test_auc"
      ],
      "metadata": {
        "id": "b0VX5FL_ijxC"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_auc = test(model, test_loader)\n",
        "print(f\"Test Loss: {test_loss:.4f} - Test AUC: {test_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB0Y0SNyiocq",
        "outputId": "dc1eb643-8310-476b-8d61-cf011107be2a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing\n",
            "Batch 0/92 - Loss: 0.898653507232666\n",
            "Batch 10/92 - Loss: 0.8858987092971802\n",
            "Batch 20/92 - Loss: 0.8856769800186157\n",
            "Batch 30/92 - Loss: 0.8997958898544312\n",
            "Batch 40/92 - Loss: 0.877971351146698\n",
            "Batch 50/92 - Loss: 0.8949289917945862\n",
            "Batch 60/92 - Loss: 0.8898298740386963\n",
            "Batch 70/92 - Loss: 0.8792272210121155\n",
            "Batch 80/92 - Loss: 0.8780245184898376\n",
            "Batch 90/92 - Loss: 0.8950116038322449\n",
            "Test Loss: 0.8895 - Test AUC: 0.4809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print Model Summary"
      ],
      "metadata": {
        "id": "W2202ums11ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj6fmLtCt1Dt",
        "outputId": "0b69dd9e-4e16-454f-dab5-6f46221cd62a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 85,473,794 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save model weights"
      ],
      "metadata": {
        "id": "Nlyn6bL_2BQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the path where you want to save the model\n",
        "save_path = '/content/drive/MyDrive/ActigraphyTransformer/Modeling/Class Benzos/Smoothed Data/[Smoothed]ViViT/smooth_vivit_pretrained_model_weights.pth'\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f'Model weights saved to {save_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXrqHyI42AUu",
        "outputId": "74cec08a-387c-41b1-8f57-88c98e8a4b82"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights saved to /content/drive/MyDrive/ActigraphyTransformer/Modeling/Class Benzos/Smoothed Data/[Smoothed]ViViT/smooth_vivit_pretrained_model_weights.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RvEsA15eRtA6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}